# 论文查重工具

一个基于 TF-IDF 与余弦相似度的文本重复率检测工具，可用于论文、文本抄袭检测等场景。


## 功能特性
- **模块化设计**：拆分为文件操作、文本预处理、相似度计算三大模块，便于维护与扩展。
- **命令行交互**：通过命令行参数指定原文、抄袭版、结果文件路径，使用灵活。
- **鲁棒性强**：支持多编码文件读取，能处理空文本、特殊字符等边缘情况。
- **中文适配**：集成 `jieba` 分词与内置停用词表，对中文文本检测友好。


## 使用方式
通过命令行传入三个文件路径（原文、抄袭版、结果输出文件）：
```bash
python main.py "原文路径" "抄袭版路径" "结果输出路径"
```

示例：
```bash
python main.py "D:\test\orig.txt" "D:\test\copy.txt" "D:\test\result.txt"
```


## 依赖库
运行需安装以下 Python 库：
- `jieba`：中文分词
- `scikit-learn`：TF-IDF 与余弦相似度计算
- `numpy`：数值计算（`scikit-learn` 依赖）

安装命令：
```bash
pip install jieba scikit-learn numpy
```


## 核心流程
1. **文件读取**：自动尝试多种编码（如 UTF-8、GBK 等）读取原文和抄袭版文件。
2. **文本预处理**：清洗特殊字符、HTML 标签，进行分词并过滤停用词。
3. **相似度计算**：通过 TF-IDF 将文本向量化，再用余弦相似度算法计算重复率。
4. **结果输出**：将保留两位小数的相似度结果写入指定文件。
